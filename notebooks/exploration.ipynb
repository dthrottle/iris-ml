{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc171b1",
   "metadata": {},
   "source": [
    "# Iris Dataset Exploration\n",
    "\n",
    "This notebook provides an in-depth exploration of the Iris dataset, including:\n",
    "- Data loading and basic statistics\n",
    "- Feature distributions and visualizations\n",
    "- Correlation analysis\n",
    "- Model comparison\n",
    "- Feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d12d18",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['species'] = [target_names[i] for i in y]\n",
    "df['target'] = y\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFeature Names:\", feature_names)\n",
    "print(\"\\nTarget Classes:\", target_names)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1910089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Features: {len(feature_names)}\")\n",
    "print(f\"Classes: {len(target_names)}\")\n",
    "\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['species'].value_counts())\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb89d6da",
   "metadata": {},
   "source": [
    "## 2. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f6ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Feature Distributions by Species', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    # Histogram with KDE\n",
    "    for species in target_names:\n",
    "        data = df[df['species'] == species][feature]\n",
    "        axes[row, col].hist(data, alpha=0.6, label=species, bins=15)\n",
    "    \n",
    "    axes[row, col].set_xlabel(feature)\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "    axes[row, col].legend()\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4509ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for feature distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Feature Box Plots by Species', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    sns.boxplot(data=df, x='species', y=feature, ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'{feature} Distribution')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d336ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[feature_names].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={'shrink': 0.8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d867195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for feature relationships\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(df, hue='species', diag_kind='hist', height=2.5)\n",
    "plt.suptitle('Feature Pair Relationships', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f22dd4",
   "metadata": {},
   "source": [
    "## 3. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8856f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Create PCA DataFrame\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['species'] = [target_names[i] for i in y]\n",
    "\n",
    "# Plot PCA results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# PCA scatter plot\n",
    "plt.subplot(1, 2, 1)\n",
    "for species in target_names:\n",
    "    subset = pca_df[pca_df['species'] == species]\n",
    "    plt.scatter(subset['PC1'], subset['PC2'], label=species, alpha=0.7, s=50)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('PCA: First Two Principal Components')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Explained variance plot\n",
    "plt.subplot(1, 2, 2)\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X)\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'bo-')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA: Explained Variance Ratio')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(1, len(cumulative_variance) + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Explained variance by component: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance (first 2 components): {sum(pca.explained_variance_ratio_):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1cb90",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cba9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features for SVM and Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'Random Forest':\n",
    "        # Random Forest doesn't need scaling\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    else:\n",
    "        # SVM and Logistic Regression benefit from scaling\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    \n",
    "    test_accuracy = (y_pred == y_test).mean()\n",
    "    \n",
    "    results[name] = {\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'CV Mean': cv_scores.mean(),\n",
    "        'CV Std': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    predictions[name] = y_pred\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Model Comparison Results:\")\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ed19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Test accuracy comparison\n",
    "test_accuracies = [results[model]['Test Accuracy'] for model in models.keys()]\n",
    "model_names = list(models.keys())\n",
    "\n",
    "bars = axes[0].bar(model_names, test_accuracies, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[0].set_ylabel('Test Accuracy')\n",
    "axes[0].set_title('Model Test Accuracy Comparison')\n",
    "axes[0].set_ylim(0.9, 1.0)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, test_accuracies):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
    "                f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Cross-validation scores with error bars\n",
    "cv_means = [results[model]['CV Mean'] for model in models.keys()]\n",
    "cv_stds = [results[model]['CV Std'] for model in models.keys()]\n",
    "\n",
    "bars2 = axes[1].bar(model_names, cv_means, yerr=cv_stds, \n",
    "                   color=['skyblue', 'lightcoral', 'lightgreen'], \n",
    "                   capsize=5, alpha=0.8)\n",
    "axes[1].set_ylabel('Cross-Validation Accuracy')\n",
    "axes[1].set_title('Cross-Validation Performance (5-fold)')\n",
    "axes[1].set_ylim(0.9, 1.0)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, mean, std in zip(bars2, cv_means, cv_stds):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.002, \n",
    "                f'{mean:.3f}±{std:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, (name, y_pred) in enumerate(predictions.items()):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=target_names, yticklabels=target_names,\n",
    "                ax=axes[i])\n",
    "    axes[i].set_title(f'{name}\\nAccuracy: {results[name][\"Test Accuracy\"]:.3f}')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee8705",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = rf_model.feature_importances_\n",
    "feature_names_short = [name.replace(' (cm)', '').replace(' ', '\\n') for name in feature_names]\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(feature_names_short, feature_importance, color='skyblue', alpha=0.8)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, importance in zip(bars, feature_importance):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "             f'{importance:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance ranking\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance Ranking:\")\n",
    "for i, (_, row) in enumerate(importance_df.iterrows(), 1):\n",
    "    print(f\"{i}. {row['Feature']}: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb1515",
   "metadata": {},
   "source": [
    "## 6. Decision Boundary Visualization (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a975b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the two most important features for 2D visualization\n",
    "top_features_idx = np.argsort(feature_importance)[-2:]  # Top 2 features\n",
    "X_2d = X[:, top_features_idx]\n",
    "feature_names_2d = [feature_names[i] for i in top_features_idx]\n",
    "\n",
    "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(\n",
    "    X_2d, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train models on 2D data\n",
    "models_2d = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, (name, model) in enumerate(models_2d.items()):\n",
    "    # Train model\n",
    "    if name == 'Random Forest':\n",
    "        model.fit(X_train_2d, y_train_2d)\n",
    "    else:\n",
    "        scaler_2d = StandardScaler()\n",
    "        X_train_2d_scaled = scaler_2d.fit_transform(X_train_2d)\n",
    "        model.fit(X_train_2d_scaled, y_train_2d)\n",
    "    \n",
    "    # Create mesh for decision boundary\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    if name == 'Random Forest':\n",
    "        Z = model.predict(mesh_points)\n",
    "    else:\n",
    "        mesh_points_scaled = scaler_2d.transform(mesh_points)\n",
    "        Z = model.predict(mesh_points_scaled)\n",
    "    \n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    axes[i].contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.RdYlBu)\n",
    "    \n",
    "    # Plot data points\n",
    "    scatter = axes[i].scatter(X_2d[:, 0], X_2d[:, 1], c=y, \n",
    "                             cmap=plt.cm.RdYlBu, edgecolors='black', alpha=0.8)\n",
    "    \n",
    "    axes[i].set_xlabel(feature_names_2d[0])\n",
    "    axes[i].set_ylabel(feature_names_2d[1])\n",
    "    axes[i].set_title(f'{name} Decision Boundary')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4607b5",
   "metadata": {},
   "source": [
    "## 7. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"IRIS DATASET EXPLORATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n📊 DATASET CHARACTERISTICS:\")\n",
    "print(f\"• Total samples: {len(df)}\")\n",
    "print(f\"• Features: {len(feature_names)}\")\n",
    "print(f\"• Classes: {len(target_names)} (balanced dataset)\")\n",
    "print(f\"• No missing values\")\n",
    "\n",
    "print(\"\\n🔍 KEY INSIGHTS:\")\n",
    "print(f\"• Most important features: {', '.join(importance_df['Feature'].head(2).tolist())}\")\n",
    "print(f\"• Petal measurements are more discriminative than sepal measurements\")\n",
    "print(f\"• First 2 PCA components explain {sum(pca.explained_variance_ratio_):.1%} of variance\")\n",
    "print(f\"• Strong correlation between petal length and width ({correlation_matrix.loc['petal length (cm)', 'petal width (cm)']:.3f})\")\n",
    "\n",
    "print(\"\\n🎯 MODEL PERFORMANCE:\")\n",
    "best_model = max(results.keys(), key=lambda x: results[x]['Test Accuracy'])\n",
    "best_accuracy = results[best_model]['Test Accuracy']\n",
    "print(f\"• Best performing model: {best_model} ({best_accuracy:.3f} accuracy)\")\n",
    "print(f\"• All models achieve >93% accuracy\")\n",
    "print(f\"• Setosa is easily separable from other species\")\n",
    "print(f\"• Versicolor and Virginica have some overlap\")\n",
    "\n",
    "print(\"\\n💡 RECOMMENDATIONS:\")\n",
    "print(\"• Random Forest is recommended for this dataset (no scaling required, robust)\")\n",
    "print(\"• Petal measurements alone could achieve good classification\")\n",
    "print(\"• Consider ensemble methods for production use\")\n",
    "print(\"• Feature engineering not necessary - original features are sufficient\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
