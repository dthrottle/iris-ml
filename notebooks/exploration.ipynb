{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc171b1",
   "metadata": {},
   "source": [
    "# Iris Dataset Exploration\n",
    "\n",
    "This notebook provides an in-depth exploration of the Iris dataset, including:\n",
    "- Data loading and basic statistics\n",
    "- Feature distributions and visualizations\n",
    "- Correlation analysis\n",
    "- Model comparison\n",
    "- Feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d12d18",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['species'] = [target_names[i] for i in y]\n",
    "df['target'] = y\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFeature Names:\", feature_names)\n",
    "print(\"\\nTarget Classes:\", target_names)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1910089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Features: {len(feature_names)}\")\n",
    "print(f\"Classes: {len(target_names)}\")\n",
    "\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['species'].value_counts())\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb89d6da",
   "metadata": {},
   "source": [
    "## 2. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f6ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Feature Distributions by Species', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    # Histogram with KDE\n",
    "    for species in target_names:\n",
    "        data = df[df['species'] == species][feature]\n",
    "        axes[row, col].hist(data, alpha=0.6, label=species, bins=15)\n",
    "    \n",
    "    axes[row, col].set_xlabel(feature)\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "    axes[row, col].legend()\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4509ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for feature distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Feature Box Plots by Species', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    sns.boxplot(data=df, x='species', y=feature, ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'{feature} Distribution')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d336ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[feature_names].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={'shrink': 0.8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d867195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for feature relationships\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(df, hue='species', diag_kind='hist', height=2.5)\n",
    "plt.suptitle('Feature Pair Relationships', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f22dd4",
   "metadata": {},
   "source": [
    "## 3. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8856f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Create PCA DataFrame\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['species'] = [target_names[i] for i in y]\n",
    "\n",
    "# Plot PCA results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# PCA scatter plot\n",
    "plt.subplot(1, 2, 1)\n",
    "for species in target_names:\n",
    "    subset = pca_df[pca_df['species'] == species]\n",
    "    plt.scatter(subset['PC1'], subset['PC2'], label=species, alpha=0.7, s=50)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('PCA: First Two Principal Components')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Explained variance plot\n",
    "plt.subplot(1, 2, 2)\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X)\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'bo-')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA: Explained Variance Ratio')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(1, len(cumulative_variance) + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Explained variance by component: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance (first 2 components): {sum(pca.explained_variance_ratio_):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1cb90",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cba9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features for SVM and Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'Random Forest':\n",
    "        # Random Forest doesn't need scaling\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    else:\n",
    "        # SVM and Logistic Regression benefit from scaling\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    \n",
    "    test_accuracy = (y_pred == y_test).mean()\n",
    "    \n",
    "    results[name] = {\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'CV Mean': cv_scores.mean(),\n",
    "        'CV Std': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    predictions[name] = y_pred\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Model Comparison Results:\")\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ed19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Test accuracy comparison\n",
    "test_accuracies = [results[model]['Test Accuracy'] for model in models.keys()]\n",
    "model_names = list(models.keys())\n",
    "\n",
    "bars = axes[0].bar(model_names, test_accuracies, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[0].set_ylabel('Test Accuracy')\n",
    "axes[0].set_title('Model Test Accuracy Comparison')\n",
    "axes[0].set_ylim(0.9, 1.0)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, test_accuracies):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
    "                f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Cross-validation scores with error bars\n",
    "cv_means = [results[model]['CV Mean'] for model in models.keys()]\n",
    "cv_stds = [results[model]['CV Std'] for model in models.keys()]\n",
    "\n",
    "bars2 = axes[1].bar(model_names, cv_means, yerr=cv_stds, \n",
    "                   color=['skyblue', 'lightcoral', 'lightgreen'], \n",
    "                   capsize=5, alpha=0.8)\n",
    "axes[1].set_ylabel('Cross-Validation Accuracy')\n",
    "axes[1].set_title('Cross-Validation Performance (5-fold)')\n",
    "axes[1].set_ylim(0.9, 1.0)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, mean, std in zip(bars2, cv_means, cv_stds):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.002, \n",
    "                f'{mean:.3f}Â±{std:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, (name, y_pred) in enumerate(predictions.items()):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=target_names, yticklabels=target_names,\n",
    "                ax=axes[i])\n",
    "    axes[i].set_title(f'{name}\\nAccuracy: {results[name][\"Test Accuracy\"]:.3f}')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee8705",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = rf_model.feature_importances_\n",
    "feature_names_short = [name.replace(' (cm)', '').replace(' ', '\\n') for name in feature_names]\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(feature_names_short, feature_importance, color='skyblue', alpha=0.8)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, importance in zip(bars, feature_importance):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "             f'{importance:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance ranking\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance Ranking:\")\n",
    "for i, (_, row) in enumerate(importance_df.iterrows(), 1):\n",
    "    print(f\"{i}. {row['Feature']}: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb1515",
   "metadata": {},
   "source": [
    "## 6. Decision Boundary Visualization (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a975b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the two most important features for 2D visualization\n",
    "top_features_idx = np.argsort(feature_importance)[-2:]  # Top 2 features\n",
    "X_2d = X[:, top_features_idx]\n",
    "feature_names_2d = [feature_names[i] for i in top_features_idx]\n",
    "\n",
    "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(\n",
    "    X_2d, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train models on 2D data\n",
    "models_2d = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, (name, model) in enumerate(models_2d.items()):\n",
    "    # Train model\n",
    "    if name == 'Random Forest':\n",
    "        model.fit(X_train_2d, y_train_2d)\n",
    "    else:\n",
    "        scaler_2d = StandardScaler()\n",
    "        X_train_2d_scaled = scaler_2d.fit_transform(X_train_2d)\n",
    "        model.fit(X_train_2d_scaled, y_train_2d)\n",
    "    \n",
    "    # Create mesh for decision boundary\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    if name == 'Random Forest':\n",
    "        Z = model.predict(mesh_points)\n",
    "    else:\n",
    "        mesh_points_scaled = scaler_2d.transform(mesh_points)\n",
    "        Z = model.predict(mesh_points_scaled)\n",
    "    \n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    axes[i].contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.RdYlBu)\n",
    "    \n",
    "    # Plot data points\n",
    "    scatter = axes[i].scatter(X_2d[:, 0], X_2d[:, 1], c=y, \n",
    "                             cmap=plt.cm.RdYlBu, edgecolors='black', alpha=0.8)\n",
    "    \n",
    "    axes[i].set_xlabel(feature_names_2d[0])\n",
    "    axes[i].set_ylabel(feature_names_2d[1])\n",
    "    axes[i].set_title(f'{name} Decision Boundary')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4607b5",
   "metadata": {},
   "source": [
    "## 7. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"IRIS DATASET EXPLORATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nðŸ“Š DATASET CHARACTERISTICS:\")\n",
    "print(f\"â€¢ Total samples: {len(df)}\")\n",
    "print(f\"â€¢ Features: {len(feature_names)}\")\n",
    "print(f\"â€¢ Classes: {len(target_names)} (balanced dataset)\")\n",
    "print(f\"â€¢ No missing values\")\n",
    "\n",
    "print(\"\\nðŸ” KEY INSIGHTS:\")\n",
    "print(f\"â€¢ Most important features: {', '.join(importance_df['Feature'].head(2).tolist())}\")\n",
    "print(f\"â€¢ Petal measurements are more discriminative than sepal measurements\")\n",
    "print(f\"â€¢ First 2 PCA components explain {sum(pca.explained_variance_ratio_):.1%} of variance\")\n",
    "print(f\"â€¢ Strong correlation between petal length and width ({correlation_matrix.loc['petal length (cm)', 'petal width (cm)']:.3f})\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ MODEL PERFORMANCE:\")\n",
    "best_model = max(results.keys(), key=lambda x: results[x]['Test Accuracy'])\n",
    "best_accuracy = results[best_model]['Test Accuracy']\n",
    "print(f\"â€¢ Best performing model: {best_model} ({best_accuracy:.3f} accuracy)\")\n",
    "print(f\"â€¢ All models achieve >93% accuracy\")\n",
    "print(f\"â€¢ Setosa is easily separable from other species\")\n",
    "print(f\"â€¢ Versicolor and Virginica have some overlap\")\n",
    "\n",
    "print(\"\\nðŸ’¡ RECOMMENDATIONS:\")\n",
    "print(\"â€¢ Random Forest is recommended for this dataset (no scaling required, robust)\")\n",
    "print(\"â€¢ Petal measurements alone could achieve good classification\")\n",
    "print(\"â€¢ Consider ensemble methods for production use\")\n",
    "print(\"â€¢ Feature engineering not necessary - original features are sufficient\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
